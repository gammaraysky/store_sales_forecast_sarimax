{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Item Demand Forecasting Challenge\n",
    "- predict 3 months of item sales at different stores\n",
    "- https://www.kaggle.com/competitions/demand-forecasting-kernels-only/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuing from previous notebook, we will implement individual SARIMAX(3,1,1)(1,1,1,7) to all item-store sets, then combine the results for submission.**\n",
    "\n",
    "**For each item-store set, will provide as exogenous data: the seasonal data from seasonal_decompose of period=365 and period=7 days, and boolean masks of special days (holidays and 7 days leading to holidays)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "test  = pd.read_csv('./data/test.csv', index_col=[0])\n",
    "train = pd.read_csv('./data/train.csv', )\n",
    "\n",
    "train['date'] = pd.to_datetime(train['date'], format=\"%Y-%m-%d\")\n",
    "test['date']  = pd.to_datetime(test['date'], format=\"%Y-%m-%d\")\n",
    "cutoff=len(train)\n",
    "\n",
    "combined = pd.concat([train,test])\n",
    "fulllength = len(combined)\n",
    "\n",
    "\n",
    "###? PREP EXOG FEATURES: \n",
    "\n",
    "#? mark US holidays, also mark 7 days before holidays as 'preholidays' as people may buy items before the holidays.\n",
    "holidays = pd.read_csv('./data/US Holiday Dates (2004-2021).csv')\n",
    "holidays.set_index('Date', inplace=True)\n",
    "\n",
    "def addholidays_fulldf(df):\n",
    "    df['holiday']    =0\n",
    "    df['preholiday'] =0\n",
    "    for d in holidays.index:\n",
    "        d = pd.to_datetime(d)\n",
    "        if d in df['date'].values:\n",
    "            df.loc[df['date']==pd.to_datetime(d), 'holiday']=1        \n",
    "            \n",
    "        if pd.to_datetime(d)-pd.Timedelta(7, \"d\") in df['date'].values:\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(1, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(2, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(3, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(4, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(5, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(6, \"d\")), 'preholiday']=1\n",
    "            df.loc[df['date']==(pd.to_datetime(d)-pd.Timedelta(7, \"d\")), 'preholiday']=1\n",
    "    return df\n",
    "\n",
    "combined = addholidays_fulldf(combined)\n",
    "train = combined.iloc[:cutoff]\n",
    "test = combined.iloc[cutoff:]\n",
    "\n",
    "\n",
    "###? PART OUT INDIVIDUAL STORE AND ITEMS INTO INDIVIDUAL TIME SERIES. E.G. i50s10 for item 50, store 10\n",
    "s_train = []\n",
    "for item in train['item'].unique():\n",
    "    for store in train['store'].unique():\n",
    "        sname = 'train' + str(item).rjust(2, '0') + 's' + str(store).rjust(2, '0')\n",
    "        tmp = train[(train['item']==item)&(train['store']==store)].copy(deep=True)\n",
    "        tmp.set_index('date', inplace=True)\n",
    "        globals()[sname] = pd.DataFrame( {'sales':tmp['sales'],'holiday':tmp['holiday'],'preholiday':tmp['preholiday']} )\n",
    "        s_train.append(sname)\n",
    "\n",
    "s_test = []\n",
    "for item in test['item'].unique():\n",
    "    for store in test['store'].unique():\n",
    "        sname = 'test' + str(item).rjust(2, '0') + 's' + str(store).rjust(2, '0')\n",
    "        tmp = test[(test['item']==item)&(test['store']==store)].copy(deep=True)\n",
    "        tmp.set_index('date', inplace=True)\n",
    "        globals()[sname] = pd.DataFrame( {'sales':tmp['sales'],'holiday':tmp['holiday'],'preholiday':tmp['preholiday']} )\n",
    "        s_test.append(sname)\n",
    "\n",
    "\n",
    "\n",
    "#? provide 365 day seasonal, 7 day seasonal,\n",
    "s_train_sd_yrly = []\n",
    "s_train_sd_wkly = []\n",
    "for item in s_train:  \n",
    "    # trn = eval(item)[:1461]\n",
    "    # tes = eval(item)[1461:]\n",
    "\n",
    "    sd_yrly = sm.tsa.seasonal_decompose(eval(item)['sales'], model='additive', period=365) # sd.trend # sd.resid # sd.seasonal\n",
    "    sd_wkly = sm.tsa.seasonal_decompose(eval(item)['sales'], model='additive', period=7)\n",
    "    s_train_sd_yrly.append(sd_yrly.seasonal)\n",
    "    s_train_sd_wkly.append(sd_wkly.seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startdate = test['date'].min()\n",
    "enddate = test['date'].max()\n",
    "\n",
    "full_predictions = pd.DataFrame()\n",
    "\n",
    "for i, item in enumerate(s_train):\n",
    "\n",
    "    product = item.split('train')[1].split('s')[0]\n",
    "    store   = item.split('train')[1].split('s')[1]\n",
    "\n",
    "    globals()[item]['sd_yrly'] = s_train_sd_yrly[i]\n",
    "    globals()[item]['sd_wkly'] = s_train_sd_wkly[i]\n",
    "    # display(globals()[item])\n",
    "\n",
    "    endog = globals()[item]['sales']\n",
    "    exog  = globals()[item][['holiday','preholiday','sd_yrly','sd_wkly']]\n",
    "\n",
    "    exog2013 = exog.loc['2013'].copy(deep=True)\n",
    "    exog2014 = exog.loc['2014'].copy(deep=True)\n",
    "    exog2015 = exog.loc['2015'].copy(deep=True)\n",
    "    exog2016 = exog.loc['2016'].copy(deep=True)\n",
    "\n",
    "    exog2014.index = exog2014.index - pd.Timedelta(365, 'days')\n",
    "    exog2015.index = exog2015.index - pd.Timedelta(365*2, 'days')\n",
    "    exog2016.index = exog2016.index - pd.Timedelta(365*3, 'days')\n",
    "\n",
    "    exog2013.reset_index(inplace=True)\n",
    "    exog2014.reset_index(inplace=True)\n",
    "    exog2015.reset_index(inplace=True)\n",
    "    exog2016.reset_index(inplace=True)\n",
    "\n",
    "    exogagg = pd.concat([exog2013,exog2014,exog2015,exog2016])\n",
    "    exogpred = exogagg.groupby('date').mean()\n",
    "\n",
    "    exog_test = test[(test['item']==1)&(test['store']==1)][['holiday','preholiday']]\n",
    "    exog_test['sd_yrly'] = exogpred['sd_yrly'][:len(exog_test)].values\n",
    "    exog_test['sd_wkly'] = exogpred['sd_wkly'][:len(exog_test)].values\n",
    "\n",
    "    # model = sm.tsa.statespace.SARIMAX(endog.asfreq(freq='1d'), order=(3,1,1), seasonal_order=(2,1,0,7), trend=None, exog=exog).fit(method='cg', max_iter=100)\n",
    "    model = sm.tsa.statespace.SARIMAX(endog, order=(3,1,1), seasonal_order=(1,1,1,7), trend=None, exog=exog).fit()\n",
    "    predictions = model.predict(start=startdate, end=enddate, exog=exog_test)\n",
    "    \n",
    "    pred_df = pd.DataFrame({'sales':predictions})\n",
    "    pred_df['item']=int(product)\n",
    "    pred_df['store']=int(store)\n",
    "    \n",
    "    full_predictions = pd.concat([full_predictions, pred_df])\n",
    "\n",
    "\n",
    "###? UPDATE PREDICTIONS INTO TEST DF.\n",
    "for row in full_predictions.iterrows():\n",
    "    # print(row[0], row[1]['sales'], row[1]['item'], row[1]['store'])\n",
    "    test.loc[\\\n",
    "        (test['store']==row[1]['store'])&\\\n",
    "        (test['item']==row[1]['item'])&\\\n",
    "        (test['date']==row[0]) , 'sales'] = row[1]['sales']\n",
    "\n",
    "\n",
    "test['sales'].to_csv('storesales2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Scores**\n",
    "- **Public Score: 17.39495 (345/459), Private score: 14.92581 (316/459)**\n",
    "- (This leaderboard is calculated with approximately 34% of the test data. The final results will be based on the other 66%.)\n",
    "- aggregated across complete test set, that's 15.76531 SMAPE score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.765317600000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17.39495*0.34 + 14.92581*0.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('python')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "481cec52f7d095282728c60bb70d451310b560bc752e0d5557e6790a59f74331"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
